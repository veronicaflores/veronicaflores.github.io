---
layout: post
title: Week 3
---

## Week 3 (July 11th - July 15th)

**July 12th:** <br/>   
On this day I met with Professor Ordóñez Román and he introduced to me 2 new vision and language models, Google's [ALIGN](https://ai.googleblog.com/2021/05/align-scaling-up-visual-and-vision.html) Model and [CoCa](https://arxiv.org/pdf/2205.01917.pdf) from Google. These two models where very interesting to read about and where very similar to the CLIP model which I have been using.
Moreover, I was asked to conduct the tests I did last week on a different CLIP model, the ViT-L/14@336px model. However, instead of using Google Collab which I had been using, I was introduced to Rice's Vision computing infrastructure where I began using python scripts to automate the evaluation of these models. 

**July 13th:** <br/> 

Here's some of the important tasks I accomplished this day:
- [x] Familiarizing myself with Rice’s Vision computing infrastructure
- [x] Installing the VPN on my computer
- [x] Installing Python into Home Directory on Server - Anaconda for Linux
- [X] Running a remote jupyter notebook
- [x] Understand screens + GPU allocation on terminal
- [x] Upload Winoground dataset into server under /scratch/vsf2
- [x] Create a python script to evaluate larger CLIP model and run it on the servers

Along with completing these tasks over the last couple of days I was able to run the python script and generate a new table for my tests.
<img width="877" alt="Screen Shot 2022-09-28 at 9 04 28 PM" src="https://user-images.githubusercontent.com/52052151/192936350-86025120-1f8f-469f-a7ed-4f71a30c0eeb.png">

